<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style/product-info.css">
    <title>Hoe Werkt Het?</title>
</head>
<body>
    <main>
        <h1><span>H</span>oe Werkt Het</h1>
        <div class="primarydivider"><span></span></div>
        <img src="img/product-info-img-ai.png" alt="">
        <p>
            Dit boek genereerd met Artificiele Inteligentie (A.I.) een sprookje voor jou of jouw kind. Wij maken gebruik van “GPT 4”, een geavanceerde chat- en schrijfmodel.
        </p>
        <p>
            Dit betekent dat wij voor je snel een verassend goed verhaal kunnen geven met onderdelen die je zelf zou willen zien in het verhaal!
        </p>
        <p>
            Generative Pre-trained Transformer (GPT) is een reeks neurale netwerkarchitecturen ontwikkeld door OpenAI, die gericht zijn op natuurlijke taalverwerkingstaken. Het idee achter GPT is om modellen te trainen om natuurlijke taal te begrijpen en te genereren, zonder specifiek te zijn voor een bepaalde taak. Het doel is om een breed scala aan taalgerelateerde taken aan te kunnen, zoals vertalingen, samenvattingen, vraag-antwoordtaken en het genereren van tekst.
        </p>
        <p>
            GPT maakt gebruik van transformer-architecturen, die bekend staan om hun vermogen om relaties en contexten in gegevens te begrijpen. Deze modellen worden in verschillende lagen gestapeld en leren van enorme hoeveelheden tekstgegevens door middel van een zelfsupervised learning-aanpak.
        </p>
        <p>
            Dit betekent dat GPT wordt getraind op een grote dataset met ongelabelde tekst, zoals artikelen, boeken, en internetteksten. Door deze data te analyseren en de onderliggende structuren te begrijpen, leert het model de patronen en regels van natuurlijke taal.
        </p>
        <p>
            Wanneer het model getraind is, kan het gebruikt worden voor verschillende taken door een prompt (instructie) te geven. Het model genereert dan een tekst die relevant is voor die prompt, gebaseerd op zijn begrip van taalstructuren en patronen in de trainingsdata.
        </p>
        <p>
            GPT-modellen hebben zich bewezen als krachtige instrumenten voor natuurlijke taalverwerking, maar ze hebben ook hun beperkingen. Soms kunnen ze onnauwkeurigheden vertonen, inconsistente antwoorden produceren of moeite hebben met het begrijpen van context in complexe zinnen of conversaties.
        </p>
        <p>
            De GPT-reeks is geëvolueerd met verschillende versies, elk met verbeteringen in modelarchitectuur, trainingsdata en prestaties in taalgerelateerde taken. Elke nieuwe versie bouwt voort op de vorige en probeert de beperkingen van het model te verbeteren om nauwkeuriger, coherenter en relevanter te zijn in zijn taalgeneratie.
        </p>
    </main>
</body>
</html>